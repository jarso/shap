{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "102718eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.6 (main, Mar 10 2023, 10:55:28) [GCC 11.3.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jarek/projects/shap/venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "import catboost\n",
    "import sklearn.ensemble\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numba\n",
    "import time\n",
    "import json\n",
    "import xgboost\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap.benchmark\n",
    "\n",
    "from shap import TreeExplainer as TreeCext\n",
    "\n",
    "from shap.explainers.pytree import *\n",
    "\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d072a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f510ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_explain(name, data, explainer, vals=False):\n",
    "    measure_time = time.perf_counter\n",
    "    start = measure_time()\n",
    "    values = explainer(data)\n",
    "    end = measure_time()\n",
    "    print(\"name: {}, time: {}\".format(name, end - start))\n",
    "    return [name, values if vals else [], end - start]\n",
    "\n",
    "def run_diff_explainers(model, data):\n",
    "    explainers = [\n",
    "        (\"Tree\", shap.explainers.Tree(model)),\n",
    "        (\"TreeBanz\", shap.explainers.Tree(model, use_banz=True)),\n",
    "        # (\"Exact\", shap.Explainer(model.predict, data)), # duzo za wolne\n",
    "    ]\n",
    "\n",
    "    return [run_explain(name, data, exp) for name, exp in explainers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dede946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e43a06ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_explain2(name, data, explainer):\n",
    "    measure_time = time.perf_counter\n",
    "    start = measure_time()\n",
    "    values = explainer(data)\n",
    "    end = measure_time()\n",
    "    print(\"name: {}, time: {}\".format(name, end - start))\n",
    "    return [name, values, end - start]\n",
    "\n",
    "def run_diff_explainers2(model, data):\n",
    "\n",
    "#     # use an independent masker\n",
    "#     masker = shap.maskers.Independent(X_train)\n",
    "#     pmasker = shap.maskers.Partition(X_train)\n",
    "    explainers = [\n",
    "        (\"Tree\", shap.explainers.Tree(model)),\n",
    "        (\"TreeBanz\", shap.explainers.Tree(model,  use_banz=True)),\n",
    "        (\"NEW TreeBanz\", shap.explainers.Tree(model,  use_banz=True, change_deltas=True)),\n",
    "    #     (\"Tree approx.\", shap.explainers.Tree(model, masker, approximate=True)),\n",
    "    #     (\"Exact\", shap.explainers.Exact(model.predict, masker)),\n",
    "    ]\n",
    "\n",
    "    return [run_explain2(name, data, exp) for name, exp in explainers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a1f0678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
      "13\n",
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "# X,y = shap.datasets.communitiesandcrime()\n",
    "X,y = shap.datasets.boston()\n",
    "print(X.columns.values.tolist())\n",
    "print(len(X.columns.values.tolist()))\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b594289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,y = shap.datasets.boston()\n",
    "# X = X.values\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# model = sklearn.ensemble.RandomForestRegressor(n_estimators=1000, max_depth=13)\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# TreeBanzCext = shap.explainers.Tree(model, use_banz=True, change_deltas=True)\n",
    "# TreeBanzCext(X_test)\n",
    "\n",
    "1\n",
    "# ex = TreeExplainer(model)\n",
    "# res_banz_py = ex.banz_values(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694370f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zobaczmy na tym datasecie jaka glebokosc daje najlepsze wyszkolenie\n",
    "\n",
    "# X,y = shap.datasets.boston()\n",
    "# X = X.values\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# scores = {}\n",
    "# mean = 5\n",
    "\n",
    "# for i in range(1,13):\n",
    "#     pass\n",
    "#     print(i)\n",
    "#     scores[i] = 0\n",
    "#     for j in range(mean):\n",
    "#         model = sklearn.ensemble.RandomForestRegressor(n_estimators=1000, max_depth=i)\n",
    "#         model.fit(X_train, y_train)\n",
    "#         scores[i] = scores[i] + model.score(X_test, y_test)\n",
    "#     scores[i] = scores[i] / mean\n",
    "\n",
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1009a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_generator(json_input, lookup_key):\n",
    "    if isinstance(json_input, dict):\n",
    "        for k, v in json_input.items():\n",
    "            if k == lookup_key:\n",
    "                yield v\n",
    "            else:\n",
    "                yield from item_generator(v, lookup_key)\n",
    "    elif isinstance(json_input, list):\n",
    "        for item in json_input:\n",
    "            yield from item_generator(item, lookup_key)\n",
    "\n",
    "def tree_depth(json_text):\n",
    "    json_input = json.loads(json_text)\n",
    "    return max(list(item_generator(json_input, 'depth'))) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f9a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap.datasets as ds\n",
    "\n",
    "def a(x):\n",
    "    X, y = x\n",
    "    print(X.shape)\n",
    "\n",
    "a(ds.adult())\n",
    "a(ds.boston())\n",
    "a(ds.communitiesandcrime())\n",
    "a(ds.corrgroups60())\n",
    "a(ds.diabetes())\n",
    "a(ds.imagenet50())\n",
    "# a(ds.imdb())\n",
    "a(ds.independentlinear60())\n",
    "a(ds.iris())\n",
    "a(ds.nhanesi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c260fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zobaczmy na tym datasecie jaka glebokosc daje najlepsze wyszkolenie\n",
    "\n",
    "X,y = shap.datasets.nhanesi()\n",
    "X = X.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7, test_size=0.2)\n",
    "\n",
    "xgb_full = xgboost.DMatrix(X, label=y)\n",
    "xgb_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "xgb_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "\n",
    "scores = {}\n",
    "mean_depths = {}\n",
    "stddev_depths = {}\n",
    "full_depths = {}\n",
    "\n",
    "mean = 10\n",
    "\n",
    "for i in range(1,2,1):\n",
    "# for i in range(1,32,1):\n",
    "    print(i)\n",
    "    scores[i] = 0\n",
    "    mean_depths[i] = 0\n",
    "    stddev_depths[i] = 0\n",
    "    for j in range(mean):\n",
    "        params = {\n",
    "            \"eta\": 0.002,\n",
    "            \"max_depth\": 3,\n",
    "            \"objective\": \"survival:cox\",\n",
    "            \"subsample\": 0.5\n",
    "        }\n",
    "#         model = xgboost.train(params, xgb_train, 10000, evals = [(xgb_test, \"test\")], verbose_eval=1000)\n",
    "        model = xgboost.XGBRegressor(n_estimators=1000, max_depth=i, subsample=0.5)\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False, early_stopping_rounds=10)\n",
    "        scores[i] = scores[i] + model.score(X_test, y_test)\n",
    "        \n",
    "        booster = model.get_booster()\n",
    "        tree_df = booster.trees_to_dataframe()\n",
    "#         print(\"rysuje drzewo\")\n",
    "#         xgboost.plotting.plot_tree(booster)\n",
    "#         print(booster.get_dump(dump_format = \"json\").head())\n",
    "        depths = [tree_depth(x) for x in booster.get_dump(dump_format = \"json\")]\n",
    "        full_depths[i] = depths\n",
    "        mean_depths[i] = mean_depths[i] + np.mean(depths)\n",
    "        stddev_depths[i] = stddev_depths[i] + np.std(depths)\n",
    "        \n",
    "    scores[i] = scores[i] / mean\n",
    "    mean_depths[i] = mean_depths[i] / mean\n",
    "    stddev_depths[i] = stddev_depths[i] / mean\n",
    "\n",
    "print(scores)\n",
    "# print(mean_depths)\n",
    "# print(stddev_depths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8963df53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#przyklad lundberga:\n",
    "X,y = shap.datasets.nhanesi()\n",
    "X_display,y_display = shap.datasets.nhanesi(display=True) # human readable feature values\n",
    "\n",
    "xgb_full = xgboost.DMatrix(X, label=y)\n",
    "\n",
    "# create a train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "xgb_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "xgb_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# use validation set to choose # of trees\n",
    "params = {\n",
    "    \"eta\": 0.002,\n",
    "    \"max_depth\": 3,\n",
    "    \"objective\": \"survival:cox\",\n",
    "    \"subsample\": 0.5\n",
    "}\n",
    "# model_train = xgboost.train(params, xgb_train, 10000, evals = [(xgb_test, \"test\")], verbose_eval=1000)\n",
    "\n",
    "# train final model on the full data set\n",
    "params = {\n",
    "    \"eta\": 0.002,\n",
    "    \"max_depth\": 3, \n",
    "    \"objective\": \"survival:cox\",\n",
    "    \"subsample\": 0.5\n",
    "}\n",
    "model_full = xgboost.train(params, xgb_full, 5000, evals = [(xgb_full, \"test\")], verbose_eval=1000)\n",
    "\n",
    "def c_statistic_harrell(pred, labels):\n",
    "    total = 0\n",
    "    matches = 0\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            if labels[j] > 0 and abs(labels[i]) > labels[j]:\n",
    "                total += 1\n",
    "                if pred[j] > pred[i]:\n",
    "                    matches += 1\n",
    "    return matches/total\n",
    "\n",
    "# see how well we can order people by survival\n",
    "c_statistic_harrell(model_full.predict(xgb_test, ntree_limit=5000), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a45d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "res = model_full.predict(xgb_test)\n",
    "\n",
    "print(np.sqrt(MSE(res, y_test)))\n",
    "print(r2_score(res, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5659dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid = pd.read_csv('../../data/Covid Data.csv')\n",
    "\n",
    "print(covid.shape)\n",
    "\n",
    "cols = ['PNEUMONIA','DIABETES', 'COPD', 'ASTHMA', 'INMSUPR','HIPERTENSION', \n",
    "        'OTHER_DISEASE', 'CARDIOVASCULAR', 'OBESITY','RENAL_CHRONIC', 'TOBACCO']\n",
    "for col in cols :\n",
    "    covid = covid[(covid[col] == 1)|(covid[col] == 2)]\n",
    "    \n",
    "covid['DEATH'] = [2 if row=='9999-99-99' else 1 for row in covid['DATE_DIED']]\n",
    "\n",
    "covid['DEATH'].value_counts()\n",
    "\n",
    "covid.drop(columns=['INTUBED','ICU','DATE_DIED'],inplace=True)\n",
    "\n",
    "covid['PREGNANT'] = covid['PREGNANT'].replace(97,2)\n",
    "covid['PREGNANT'] = covid['PREGNANT'].replace(98,2)\n",
    "\n",
    "y = covid['CLASIFFICATION_FINAL']\n",
    "X = covid.drop('CLASIFFICATION_FINAL', axis=1)\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9bc407",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "print(\"training\")\n",
    "log_reg.fit(X_train, y_train)\n",
    "print(\"testing\")\n",
    "print(\"Logistic Regression Accuracy :\", log_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a41929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7036657f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=13\n",
    "model = sklearn.ensemble.RandomForestClassifier(max_depth=i)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"{}: {}\\n--------------------------------\".format(i, model.score(X_test, y_test)))\n",
    "model_default = sklearn.ensemble.RandomForestClassifier()\n",
    "model_default.fit(X_train, y_train)\n",
    "model_default.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c002fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd3377",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(25,26,20):\n",
    "    X_2 = X_test[:i]\n",
    "    print(\"{}: {}\".format(i, X_2.shape))\n",
    "    start = time.time()\n",
    "    run_diff_explainers(model, X_2)\n",
    "    run_diff_explainers(model_default, X_2)\n",
    "    print(time.time()-start)\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e0e562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131792b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# model = xgboost.XGBClassifier(max_depth=13)\n",
    "model_xgb = xgboost.XGBClassifier()\n",
    "start = time.time()\n",
    "model_xgb.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(\"time to train: {}\".format(end))\n",
    "model_xgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e01e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e18d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_diff_explainers(model_xgb, X_test)\n",
    "13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dbb66e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a023f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "X, y = load_wine(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3)\n",
    "\n",
    "model = sklearn.ensemble.RandomForestClassifier()\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(\"time to train: {}\".format(end))\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b554ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_diff_explainers(model, X)\n",
    "13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b455e9",
   "metadata": {},
   "source": [
    "## FRAUD DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79ace7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "df = pd.read_csv('../../data/Base.csv')\n",
    "# remove \"device_fraud_count\"\n",
    "df = df.drop(['device_fraud_count'], axis=1, errors='ignore') # It's 0 for all rows\n",
    "\n",
    "df['fraud_bool'].value_counts()\n",
    "\n",
    "X = df.drop(['fraud_bool'], axis=1)\n",
    "y = df['fraud_bool']\n",
    "\n",
    "\n",
    "# Train test split by 'month', month 0-5 are train, 6-7 are test data as proposed in the paper\n",
    "X_train = X[X['month']<6]\n",
    "X_test = X[X['month']>=6]\n",
    "y_train = y[X['month']<6]\n",
    "y_test = y[X['month']>=6]\n",
    "\n",
    "X_train.drop('month', axis=1, inplace=True)\n",
    "X_test.drop('month', axis=1, inplace=True)\n",
    "\n",
    "# y_train = le.fit_transform(y_train)\n",
    "# y_test = le.fit_transform(y_test)\n",
    "\n",
    "# onehot encoding for categorical variables\n",
    "s = (X_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "ohe_cols_train = pd.DataFrame(ohe.fit_transform(X_train[object_cols]))\n",
    "ohe_cols_test = pd.DataFrame(ohe.transform(X_test[object_cols]))\n",
    "\n",
    "ohe_cols_train.index = X_train.index\n",
    "ohe_cols_test.index = X_test.index\n",
    "\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_test = X_test.drop(object_cols, axis=1)\n",
    "\n",
    "X_train = pd.concat([num_X_train, ohe_cols_train], axis=1)\n",
    "X_test = pd.concat([num_X_test, ohe_cols_test], axis=1)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ranfor = sklearn.ensemble.RandomForestClassifier(max_depth=1)\n",
    "start = time.process_time()\n",
    "model_ranfor.fit(X_train, y_train)\n",
    "end = time.process_time() - start\n",
    "print(\"time to train: {}\".format(end))\n",
    "model_ranfor.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d03ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "TreeShap = shap.explainers.Tree(model_ranfor)\n",
    "TreeBanz = shap.explainers.Tree(model_ranfor, use_banz=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2338e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(100, 1001, 300):\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c48baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accurs = {}\n",
    "# for i in range(1,10):\n",
    "#     for j in range(100, 1001, 300):\n",
    "#         print(\"depth={}, n_est={}\".format(i, j))\n",
    "#         model = sklearn.ensemble.RandomForestClassifier(max_depth=i, n_estimators=j)\n",
    "#         start = time.process_time()\n",
    "#         model.fit(X_train, y_train)\n",
    "#         end = time.process_time() - start\n",
    "#         print(\"time to train: {}\".format(end))\n",
    "#         score = model.score(X_test, y_test)\n",
    "#         print(\"score:{}\".format(score))\n",
    "#         accurs[(i, j)] = score\n",
    "#         if score > 0.95:\n",
    "#             print(\"skipping more estimators...\")\n",
    "#             break\n",
    "\n",
    "# # ts = TreeShap(X_test[0])\n",
    "# accurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288df278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6cea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TreeBanz(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562ee3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "run_diff_explainers(model_ranfor, X_test[:100])\n",
    "13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28ea5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [x.get_depth() for x in model_ranfor.estimators_]\n",
    "print(np.mean(depths))\n",
    "print(np.std(depths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da19988",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.ensemble.RandomForestClassifier()\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(\"time to train: {}\".format(end))\n",
    "print(\"score:{}\".format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_test.shape)\n",
    "# run_diff_explainers(model, X_test[:1000])\n",
    "\n",
    "# depths = [x.get_depth() for x in model.estimators_]\n",
    "# print(np.mean(depths))\n",
    "# print(np.std(depths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81687b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_diff_explainers(model, X_test[:10])\n",
    "13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a182853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e4df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(learning_rate=0.09,max_depth=-5,random_state=42)\n",
    "model.fit(X_train,y_train,eval_set=[(X_test,y_test),(X_train,y_train)],\n",
    "          verbose=20,eval_metric='logloss')\n",
    "print('Testing accuracy {:.4f}'.format(model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50753c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_diff_explainers(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df5f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(learning_rate=0.09,max_depth=2,random_state=42)\n",
    "model.fit(X_train,y_train,eval_set=[(X_test,y_test),(X_train,y_train)],\n",
    "          verbose=20,eval_metric='logloss')\n",
    "print('Testing accuracy {:.4f}'.format(model.score(X_test,y_test)))\n",
    "run_diff_explainers(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef89fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594dada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgboost.XGBClassifier()\n",
    "start = time.time()\n",
    "model_xgb.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(\"time to train: {}\".format(end))\n",
    "model_xgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbf1d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_diff_explainers(model_xgb, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e881991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgboost.XGBClassifier(max_depth=2)\n",
    "start = time.time()\n",
    "model_xgb.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(\"time to train: {}\".format(end))\n",
    "model_xgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d796dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_diff_explainers(model_xgb, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7a5ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012fde03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "model_cat = catboost.CatBoostClassifier()\n",
    "start = time.time()\n",
    "model_cat.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(\"time to train: {}\".format(end))\n",
    "model_cat.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db0be13",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_diff_explainers(model_cat, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d419991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "model_cat = catboost.CatBoostClassifier(max_depth=1)\n",
    "start = time.time()\n",
    "model_cat.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(\"time to train: {}\".format(end))\n",
    "model_cat.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aebcc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_diff_explainers(model_cat, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a23a4c6",
   "metadata": {},
   "source": [
    "## Zbiorcze wykresy dla fraud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d06eae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_cat = catboost.CatBoostClassifier()\n",
    "model_cat.fit(X_train, y_train)\n",
    "model_cat.score(X_test, y_test)\n",
    "run_diff_explainers(model_cat, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927e27af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgbm = lgb.LGBMClassifier(random_state=42)\n",
    "model_lgbm.fit(X_train,y_train,eval_set=[(X_test,y_test),(X_train,y_train)],\n",
    "          verbose=20,eval_metric='logloss')\n",
    "# model_lgbm.fit(X_train, y_train)\n",
    "model_lgbm.score(X_test, y_test)\n",
    "run_diff_explainers(model_lgbm, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cba2fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracies_classifiers(X_train, y_train, X_test, y_test):\n",
    "    to_return = {}\n",
    "    models = {}\n",
    "    \n",
    "    print(\"running cat...\")\n",
    "    model_cat = catboost.CatBoostClassifier(logging_level='Silent')\n",
    "    model_cat.fit(X_train, y_train)\n",
    "    to_return['cat'] = model_cat.score(X_test, y_test)\n",
    "    models['cat'] = model_cat\n",
    "    print(\"done\") \n",
    "\n",
    "    print(\"running lbgm...\")\n",
    "    model_lgbm = lgb.LGBMClassifier(random_state=42)\n",
    "    model_lgbm.fit(X_train,y_train,eval_set=[(X_test,y_test),(X_train,y_train)],\n",
    "              verbose=20,eval_metric='logloss')\n",
    "    to_return['lbgm'] = model_lgbm.score(X_test, y_test)\n",
    "    models['lbgm'] = model_lgbm\n",
    "    print(\"done\")    \n",
    "    \n",
    "    print(\"running xgb...\")\n",
    "    model_xgb = xgboost.XGBClassifier()\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    to_return['xgb'] = model_xgb.score(X_test, y_test)\n",
    "    models['xgb'] = model_xgb\n",
    "    print(\"done\")\n",
    "    \n",
    "    print(\"running random forest...\")\n",
    "    model = sklearn.ensemble.RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    to_return['forest'] = model.score(X_test, y_test)\n",
    "    models['forest'] = model\n",
    "    print(\"done\")\n",
    "\n",
    "    \n",
    "    return (to_return, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b390c6cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running cat...\n",
      "done\n",
      "running lbgm...\n",
      "[20]\ttraining's binary_logloss: 0.0439745\tvalid_0's binary_logloss: 0.0578568\n",
      "[40]\ttraining's binary_logloss: 0.041546\tvalid_0's binary_logloss: 0.0560973\n",
      "[60]\ttraining's binary_logloss: 0.0399934\tvalid_0's binary_logloss: 0.0556541\n",
      "[80]\ttraining's binary_logloss: 0.0387201\tvalid_0's binary_logloss: 0.0557005\n",
      "[100]\ttraining's binary_logloss: 0.0375684\tvalid_0's binary_logloss: 0.0556893\n",
      "done\n",
      "running xgb...\n",
      "done\n",
      "running random forest...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maccuracies_classifiers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36maccuracies_classifiers\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunning random forest...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mensemble\u001b[38;5;241m.\u001b[39mRandomForestClassifier()\n\u001b[0;32m---> 29\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m to_return[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforest\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mscore(X_test, y_test)\n\u001b[1;32m     31\u001b[0m models[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforest\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model\n",
      "File \u001b[0;32m~/projects/shap/venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/projects/shap/venv/lib/python3.10/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/shap/venv/lib/python3.10/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/shap/venv/lib/python3.10/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/projects/shap/venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/projects/shap/venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/shap/venv/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/projects/shap/venv/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/projects/shap/venv/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/shap/venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    187\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 189\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/projects/shap/venv/lib/python3.10/site-packages/sklearn/tree/_classes.py:969\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \n\u001b[1;32m    942\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 969\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/projects/shap/venv/lib/python3.10/site-packages/sklearn/tree/_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    449\u001b[0m         splitter,\n\u001b[1;32m    450\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    456\u001b[0m     )\n\u001b[0;32m--> 458\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracies_classifiers(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "861c7989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_explainers(models, X_train, y_train, X_test, y_test):\n",
    "    to_return = {}\n",
    "    \n",
    "    print(\"running cat...\")\n",
    "    model_cat = catboost.CatBoostClassifier(logging_level='Silent')\n",
    "    model_cat.fit(X_train, y_train)\n",
    "    to_return['cat'] = run_diff_explainers(model_cat, X_test)\n",
    "    print(\"done\") \n",
    "\n",
    "    print(\"running lbgm...\")\n",
    "    model_lgbm = lgb.LGBMClassifier(random_state=42)\n",
    "    model_lgbm.fit(X_train,y_train,eval_set=[(X_test,y_test),(X_train,y_train)],\n",
    "              verbose=20,eval_metric='logloss')\n",
    "    to_return['lbgm'] = run_diff_explainers(model_lgbm, X_test)\n",
    "    print(\"done\")    \n",
    "    \n",
    "    print(\"running xgb...\")\n",
    "    model_xgb = xgboost.XGBClassifier()\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    to_return['xgb'] = run_diff_explainers(model_xgb, X_test)\n",
    "    print(\"done\")\n",
    "    \n",
    "    print(\"running random forest...\")\n",
    "    model = sklearn.ensemble.RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    to_return['forest'] = run_diff_explainers(model, X_test[:100])\n",
    "    print(\"done\")\n",
    "\n",
    "    \n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2ec40e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run_all_explainers(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23978acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_both(X_train, y_train, X_test, y_test):\n",
    "    (accuracies, models) = accuracies_classifiers(X_train, y_train, X_test, y_test)\n",
    "    print(\"scores:\")\n",
    "    print(accuracies)\n",
    "    run_all_explainers(models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "23f2c7dc",
   "metadata": {},
   "source": [
    "running lbgm...\n",
    "name: Tree, time: 32.02895050799998\n",
    "name: TreeBanz, time: 32.08172347300024\n",
    "---\n",
    "running cat...\n",
    "name: Tree, time: 32.02895050799998\n",
    "name: TreeBanz, time: 32.08172347300024\n",
    "---\n",
    "running xgb...\n",
    "name: Tree, time: 25.460610778000046\n",
    "name: TreeBanz, time: 24.96122232000016\n",
    "---\n",
    "running rand_forest...\n",
    "name: Tree, time: 103.15548725400004\n",
    "name: TreeBanz, time: 19.15706981800031\n",
    "---\n",
    "\n",
    "\n",
    "scores:\n",
    "{\n",
    " 'cat': 0.9860056289662505, \n",
    " 'lbgm': 0.9857324728916985, \n",
    " 'xgb': 0.9857519840398807, \n",
    " 'rand_forest': 0.9859812400310227\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a2bd598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running cat...\n",
      "done\n",
      "running lbgm...\n",
      "[20]\ttraining's binary_logloss: 0.0439745\tvalid_0's binary_logloss: 0.0578568\n",
      "[40]\ttraining's binary_logloss: 0.041546\tvalid_0's binary_logloss: 0.0560973\n",
      "[60]\ttraining's binary_logloss: 0.0399934\tvalid_0's binary_logloss: 0.0556541\n",
      "[80]\ttraining's binary_logloss: 0.0387201\tvalid_0's binary_logloss: 0.0557005\n",
      "[100]\ttraining's binary_logloss: 0.0375684\tvalid_0's binary_logloss: 0.0556893\n",
      "done\n",
      "running xgb...\n",
      "done\n",
      "running random forest...\n",
      "done\n",
      "scores:\n",
      "{'cat': 0.9860056289662505, 'lbgm': 0.9857324728916985, 'xgb': 0.9857519840398807, 'forest': 0.9859812400310227}\n",
      "running cat...\n",
      "ile drzew cext? 1000\n",
      "ile drzew cext? 1000\n",
      "running with BANZ=False\n",
      "name: Tree, time: 5.904360886000177\n",
      "running with BANZ=True\n",
      "name: TreeBanz, time: 5.540856431000066\n",
      "done\n",
      "running lbgm...\n",
      "[20]\ttraining's binary_logloss: 0.0439745\tvalid_0's binary_logloss: 0.0578568\n",
      "[40]\ttraining's binary_logloss: 0.041546\tvalid_0's binary_logloss: 0.0560973\n",
      "[60]\ttraining's binary_logloss: 0.0399934\tvalid_0's binary_logloss: 0.0556541\n",
      "[80]\ttraining's binary_logloss: 0.0387201\tvalid_0's binary_logloss: 0.0557005\n",
      "[100]\ttraining's binary_logloss: 0.0375684\tvalid_0's binary_logloss: 0.0556893\n",
      "ile drzew cext? 100\n",
      "ile drzew cext? 100\n",
      "running with BANZ=False\n",
      "name: Tree, time: 32.02895050799998\n",
      "running with BANZ=True\n",
      "name: TreeBanz, time: 32.08172347300024\n",
      "done\n",
      "running xgb...\n",
      "ile drzew cext? 100\n",
      "ile drzew cext? 100\n",
      "running with BANZ=False\n",
      "name: Tree, time: 25.460610778000046\n",
      "running with BANZ=True\n",
      "name: TreeBanz, time: 24.96122232000016\n",
      "done\n",
      "running random forest...\n",
      "ile drzew cext? 100\n",
      "ile drzew cext? 100\n",
      "running with BANZ=False\n",
      "using treeshap and cext\n",
      "here37\n",
      "using dense_Tree_pred\n",
      "name: Tree, time: 103.15548725400004\n",
      "running with BANZ=True\n",
      "using treeshap and cext\n",
      "using BANZ\n",
      "name: TreeBanz, time: 19.15706981800031\n",
      "done\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary -: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_both\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mrun_both\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracies)\n\u001b[0;32m----> 5\u001b[0m run_all_explainers(models, X_train, y_train, X_test, y_test)[\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m]\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary -: 'list'"
     ]
    }
   ],
   "source": [
    "run_both(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6e03bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edda39c0",
   "metadata": {},
   "source": [
    "# Wine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f550940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "X, y = load_wine(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61825e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_classifiers(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6cdd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_all_explainers(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ca66c",
   "metadata": {},
   "source": [
    "# COVID data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7665c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid = pd.read_csv('../../data/Covid Data.csv')\n",
    "\n",
    "print(covid.shape)\n",
    "\n",
    "cols = ['PNEUMONIA','DIABETES', 'COPD', 'ASTHMA', 'INMSUPR','HIPERTENSION', \n",
    "        'OTHER_DISEASE', 'CARDIOVASCULAR', 'OBESITY','RENAL_CHRONIC', 'TOBACCO']\n",
    "for col in cols :\n",
    "    covid = covid[(covid[col] == 1)|(covid[col] == 2)]\n",
    "    \n",
    "covid['DEATH'] = [2 if row=='9999-99-99' else 1 for row in covid['DATE_DIED']]\n",
    "\n",
    "covid['DEATH'].value_counts()\n",
    "\n",
    "covid.drop(columns=['INTUBED','ICU','DATE_DIED'],inplace=True)\n",
    "\n",
    "covid['PREGNANT'] = covid['PREGNANT'].replace(97,2)\n",
    "covid['PREGNANT'] = covid['PREGNANT'].replace(98,2)\n",
    "\n",
    "y = covid['CLASIFFICATION_FINAL']\n",
    "X = covid.drop('CLASIFFICATION_FINAL', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "# przeformatowujemy kategorie na od 0 do n\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5431a8ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracies_classifiers(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172d347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_all_explainers(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7437e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# koniec czesci nowej covid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27447e3",
   "metadata": {},
   "source": [
    "# Magic04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb44334",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym', 'fM3Long', 'fM3Trans', 'fAlpha', 'fDist', 'g']\n",
    "data = pd.read_csv('../../data/magic04.data', names=columns)\n",
    "labels = np.array(data['g'] == 'g', dtype=int)\n",
    "data = data.drop('g', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc25bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(set(columns) - {'g'})\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96988e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_both(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77101385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_samples_nos(models, X_train, y_train, X_test, y_test):\n",
    "    to_return = {}\n",
    "    \n",
    "#     print(\"running cat...\")\n",
    "#     model_cat = catboost.CatBoostClassifier(logging_level='Silent')\n",
    "#     model_cat.fit(X_train, y_train)\n",
    "#     for i in range(1, 10):\n",
    "#         j = i * 1000\n",
    "#         print(\"{} samples: -------------------\".format(j))\n",
    "#         run_diff_explainers(model_cat, X_test[:j])\n",
    "#     print(\"done\") \n",
    "\n",
    "#     print(\"running lbgm...\")\n",
    "#     model_lgbm = lgb.LGBMClassifier(random_state=42)\n",
    "#     model_lgbm.fit(X_train,y_train,eval_set=[(X_test,y_test),(X_train,y_train)],\n",
    "#               verbose=20,eval_metric='logloss')\n",
    "#     to_return['lbgm'] = run_diff_explainers(model_lgbm, X_test)\n",
    "#     print(\"done\")    \n",
    "    \n",
    "#     print(\"running xgb...\")\n",
    "#     model_xgb = xgboost.XGBClassifier()\n",
    "#     model_xgb.fit(X_train, y_train)\n",
    "#     to_return['xgb'] = run_diff_explainers(model_xgb, X_test)\n",
    "#     print(\"done\")\n",
    "    \n",
    "    print(\"running random forest...\")\n",
    "    model = sklearn.ensemble.RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    for i in range(1, 10):\n",
    "        j = i * 1000\n",
    "        print(\"{} samples: -------------------\".format(j))\n",
    "        run_diff_explainers(model, X_test[:j])\n",
    "    print(\"done\")\n",
    "\n",
    "    \n",
    "#     return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45818c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterate_samples_nos([], X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96cf804",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683c9870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# narysujmy sobie zaleznosc wytrenowania i glebokosci\n",
    "sns.set()\n",
    "n = max(scores) + 1\n",
    "# n = len(scores) + 1\n",
    "to_plot_scores = [0] * n\n",
    "to_plot_mean = [0] * n\n",
    "to_plot_stddev = [0] * n\n",
    "\n",
    "for i in scores.keys():\n",
    "    print(i)\n",
    "    to_plot_scores[i] = scores[i]\n",
    "    to_plot_mean[i] = mean_depths[i]\n",
    "    to_plot_stddev[i] = stddev_depths[i]\n",
    "    \n",
    "to_plot_scores.remove(0)\n",
    "to_plot_mean.remove(0)\n",
    "to_plot_stddev.remove(0)\n",
    "\n",
    "plt.title(\"Average score of models\")\n",
    "plt.ylabel(\"Accuracy in %\")\n",
    "plt.xlabel(\"Max tree depth\")\n",
    "plt.plot(to_plot_scores)\n",
    "plt.show()\n",
    "    \n",
    "# ax = sns.heatmap(quality)\n",
    "# plt.show()\n",
    "# print(to_plot_mean)\n",
    "# print(to_plot_stddev)\n",
    "\n",
    "plt.title(\"Mean depth of tree in ensemble\")\n",
    "plt.ylabel(\"Mean depth\")\n",
    "plt.xlabel(\"Max tree depth\")\n",
    "plt.errorbar(range(len(to_plot_mean)), to_plot_mean, to_plot_stddev, linestyle='None', marker='^')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbb5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprobujmy odtworzyc ten rezultat\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3)\n",
    "\n",
    "model = xgboost.XGBRegressor(n_estimators=5000, max_depth=2, subsample=0.5)\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False, early_stopping_rounds=10)\n",
    "res = model.predict(X_test)\n",
    "\n",
    "c_statistic_harrell(model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3142ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    model = xgboost.XGBRegressor(n_estimators,=1000, max_depth=i, subsample=0.5)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False, early_stopping_rounds=10)\n",
    "    res = model.predict(X_test)\n",
    "\n",
    "    print(\"{}: {}\".format(i, c_statistic_harrell(model.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e6104",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "mean_depths = {}\n",
    "stddev_depths = {}\n",
    "full_depths = {}\n",
    "\n",
    "mean = 10\n",
    "\n",
    "for i in range(1,32):\n",
    "    print(i)\n",
    "    scores[i] = 0\n",
    "    mean_depths[i] = 0\n",
    "    stddev_depths[i] = 0\n",
    "    for j in range(mean):\n",
    "        model = xgboost.XGBRegressor(n_estimators=(100+i*100), max_depth=16, subsample=0.3)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=10, verbose=False)\n",
    "        scores[i] = scores[i] + model.score(X_test, y_test)\n",
    "        \n",
    "        booster = model.get_booster()\n",
    "        tree_df = booster.trees_to_dataframe()\n",
    "#         print(\"rysuje drzewo\")\n",
    "#         xgboost.plotting.plot_tree(booster)\n",
    "        depths = [tree_depth(x) for x in booster.get_dump(dump_format = \"json\")]\n",
    "        full_depths[i] = depths\n",
    "        mean_depths[i] = mean_depths[i] + np.mean(depths)\n",
    "        stddev_depths[i] = stddev_depths[i] + np.std(depths)\n",
    "        \n",
    "    scores[i] = scores[i] / mean\n",
    "    mean_depths[i] = mean_depths[i] / mean\n",
    "    stddev_depths[i] = stddev_depths[i] / mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15eb42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5f1ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# narysujmy sobie zaleznosc wytrenowania i glebokosci w XGBoost\n",
    "sns.set()\n",
    "n = len(scores)\n",
    "to_plot_scores = [0] * n\n",
    "to_plot_mean = [0] * n\n",
    "to_plot_stddev = [0] * n\n",
    "\n",
    "for i in scores.keys():\n",
    "    to_plot_scores[i-1] = scores[i]\n",
    "    to_plot_mean[i-1] = mean_depths[i]\n",
    "    to_plot_stddev[i-1] = stddev_depths[i]\n",
    "\n",
    "plt.title(\"Average score of models\")\n",
    "plt.ylabel(\"Accuracy in %\")\n",
    "plt.xlabel(\"Max tree depth\")\n",
    "plt.plot(to_plot_scores)\n",
    "plt.show()\n",
    "    \n",
    "# ax = sns.heatmap(quality)\n",
    "# plt.show()\n",
    "# print(to_plot_mean)\n",
    "# print(to_plot_stddev)\n",
    "\n",
    "plt.title(\"Mean depth of tree in ensemble\")\n",
    "plt.ylabel(\"Mean depth\")\n",
    "plt.xlabel(\"Max tree depth\")\n",
    "plt.errorbar(range(len(to_plot_mean)), to_plot_mean, to_plot_stddev, linestyle='None', marker='^')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1db2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af13298f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_shap_cext = {}\n",
    "res_banz_cext = {}\n",
    "\n",
    "time_shap_cext = {}\n",
    "time_banz_cext = {}\n",
    "\n",
    "model_quality = {}\n",
    "\n",
    "X,y = shap.datasets.boston()\n",
    "X = X.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "for j in range (2,26,2):\n",
    "    for i in range(100, 1000, 100):\n",
    "        model = sklearn.ensemble.RandomForestRegressor(n_estimators=i, max_depth=j)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        model_quality[(i, j)] = c_statistic_harrell(model.predict(X_test), y_test)\n",
    "        \n",
    "        print(\"------------------------------\")\n",
    "        print(j, i)\n",
    "        print(\"---\")\n",
    "        \n",
    "        start = time.time()\n",
    "        res_shap_cext[(i, j)] = TreeCext(model).shap_values(X_test, banz=False)\n",
    "        time_shap_cext[(i, j)] = time.time() - start\n",
    "        print(time_shap_cext[(i, j)])\n",
    "\n",
    "        start = time.time()\n",
    "        res_banz_cext[(i, j)] = TreeCext(model).shap_values(X_test, banz=True)\n",
    "        time_banz_cext[(i, j)] = time.time() - start\n",
    "        print(time_banz_cext[(i, j)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f2ebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_shap_cext_prop = [ [time_shap_cext[(i, j)] for j in range (2,26,2)] for i in range(100, 1000, 100)]\n",
    "time_banz_cext_prop = [ [time_banz_cext[(i, j)] for j in range (2,26,2)] for i in range(100\n",
    "                                                                                        , 1000, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diffs_banz_shap = \\\n",
    "    [ [ (time_shap_cext[(i, j)] - time_banz_cext[(i, j)]) / time_shap_cext[(i, j)] * 100 \\\n",
    "       for j in range (2,26,2)] for i in range(100, 1000, 100) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5815e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "sns.heatmap(time_diffs_banz_shap, annot=True, fmt=\".1f\", linewidth=.5,\\\n",
    "           xticklabels=range(2,26,2), yticklabels=range(100, 1000, 100))\n",
    "plt.title(\"Percentage of time improvement for TreeShap vs BANZ\")\n",
    "plt.ylabel(\"No. of trees\")\n",
    "plt.xlabel(\"Max tree depth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7e0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_qualities = [[model_quality[(i, j)] for j in range (2,26,2)] for i in range(100, 1000, 100)]\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "sns.heatmap(plot_qualities, annot=True, fmt=\".3f\", linewidth=.5,\\\n",
    "           xticklabels=range(2,26,2), yticklabels=range(100, 1000, 100))\n",
    "plt.title(\"C-index quality for model\")\n",
    "plt.ylabel(\"No. of trees\")\n",
    "plt.xlabel(\"Max tree depth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9effb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_shap_cext_prop = [[res_shap_cext[(i, j)] for j in range (2,26,2)] for i in range(100, 1000, 100)]\n",
    "res_banz_cext_prop = [[res_banz_cext[(i, j)] for j in range (2,26,2)] for i in range(100, 1000, 100)]\n",
    "time_shap_cext_prop = [[time_shap_cext[(i, j)] for j in range (2,26,2)] for i in range(100, 1000, 100)]\n",
    "time_banz_cext_prop = [[time_banz_cext[(i, j)] for j in range (2,26,2)] for i in range(100, 1000, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b677c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87bcfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = shap.datasets.nhanesi()\n",
    "X = X.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7, test_size=0.2)\n",
    "\n",
    "xgb_full = xgboost.DMatrix(X, label=y)\n",
    "xgb_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "xgb_test = xgboost.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15577c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"eta\": 0.2,\n",
    "    \"max_depth\": 4, \n",
    "    \"objective\": \"survival:cox\",\n",
    "    \"subsample\": 0.5,\n",
    "}\n",
    "model_full = xgboost.train(params, xgb_full, 5000, evals = [(xgb_full, \"test\")], verbose_eval=1000,\\\n",
    "                           early_stopping_rounds=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6738d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_statistic_harrell(model_full.predict(xgb_full), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c6c77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d45d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ecb79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_diff_explainers(model_full, xgb_train, xgb_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26803f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa0e22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e56ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgboost.XGBRegressor(n_estimators=1000, max_depth=5, subsample=0.3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=10, verbose=False)\n",
    "\n",
    "booster = model.get_booster()\n",
    "tree_df = booster.trees_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a0ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x * 10 for x in scores.values()])\n",
    "plt.plot(mean_depths.values())\n",
    "plt.plot(stddev_depths.values())\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# wychodza glebokosci po 13 jak da mu sie wolna reke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31105c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58738ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f957cb49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd0bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(attributions):\n",
    "    a = attributions[1000]\n",
    "    # print(a[0][1])\n",
    "\n",
    "\n",
    "#     plt.stackplot(range(len(a[0][1].values[0])), a[0][1].values[0], a[1][1].values[0], a[2][1].values[0],\n",
    "#                  labels=[\"Tree\", \"TreeBanz\", \"NEW TreeBanz\"])\n",
    "    \n",
    "    plt.plot(range(len(a[0][1].values[0])), a[0][1].values[0])\n",
    "    plt.plot(range(len(a[0][1].values[0])), a[1][1].values[0])\n",
    "    plt.plot(range(len(a[0][1].values[0])), a[2][1].values[0])\n",
    "    \n",
    "    plt.legend()\n",
    "    # plt.subplot(a)\n",
    "    plt.show()\n",
    "\n",
    "    shap.plots.bar(a[0][1][0]) #tree\n",
    "    shap.plots.bar(a[1][1][0]) #treeBanz\n",
    "    shap.plots.bar(a[2][1][0]) #NEWtreeBanz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc6e8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X,y = shap.datasets.boston()\n",
    "X = X.values\n",
    "\n",
    "model = xgboost.XGBRegressor(n_estimators=1000, max_depth=32, subsample=0.3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=10, verbose=False)\n",
    "X_eval = X_test[:1]\n",
    "\n",
    "attributions = run_diff_explainers(model, X_train, X_eval)\n",
    "\n",
    "# show_results(attributions)\n",
    "c_statistic_harrell(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38cfd96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1eb457",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X,y = shap.datasets.nhanesi()\n",
    "X = X.values\n",
    "\n",
    "\n",
    "for i in range(1,15):\n",
    "    print(\"i={}\".format(i))\n",
    "    model = sklearn.ensemble.RandomForestRegressor(n_estimators=1000, max_depth=i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    X_eval = X_test[:1]\n",
    "\n",
    "    attributions = run_diff_explainers(model, X_train, X_eval)\n",
    "\n",
    "    y_predict = model.predict(X_test)\n",
    "    # show_results(attributions)\n",
    "    print(\"c-index:{}\".format(c_statistic_harrell(y_predict, y_test)))\n",
    "    print(\"mse:{}\".format(np.sqrt(MSE(y_predict, y_test))))\n",
    "    print(\"----------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9345d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ax = range(len(y_test))\n",
    "plt.figure(figsize=(16, 8), dpi=100)\n",
    "plt.plot(x_ax, y_test, label=\"original\")\n",
    "plt.plot(x_ax, y_predict, label=\"predicted\")\n",
    "plt.title(\"Boston dataset test and predicted data\")\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Price')\n",
    "plt.legend(loc='best',fancybox=True, shadow=True)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae4d5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = {}\n",
    "for i in range(3):\n",
    "    v[i] = [(x / attributions[1000][i][1].values[0][0]) for x in attributions[1000][i][1].values[0]]\n",
    "\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb9e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(a[0][1])\n",
    "shap.plots.beeswarm(a[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afa770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dry run to get all the code warmed up for valid runtime measurements\n",
    "# for name, exp in explainers:\n",
    "#     exp(X_eval[:1])\n",
    "\n",
    "# explain with all the explainers\n",
    "attributions = [run_explain(name, exp, X_eval) for name, exp in explainers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3156f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4422202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=400, n_features=16, n_informative=8,random_state=0, shuffle=False)\n",
    "\n",
    "model = sklearn.ensemble.RandomForestRegressor(n_estimators=1000, max_depth=10)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c255f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bst = xgboost.train({\"learning_rate\": 0.01, \"max_depth\": 4}, xgboost.DMatrix(X, label=y), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef0ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# shap_values = bst.predict(xgboost.DMatrix(X), pred_contribs=True)\n",
    "# print(time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791432a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x = X.head()\n",
    "# x = X[:1]\n",
    "x = X\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5530426",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "res_shap_cext = TreeCext(model).shap_values(X, banz=False)\n",
    "time_shap_cext = time.time() - start\n",
    "time_shap_cext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2cf1db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "res_banz_cext = TreeCext(model).shap_values(X, banz=True)\n",
    "time_banz_cext = time.time() - start\n",
    "time_banz_cext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c740851",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_shap_cext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_banz_cext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0754c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d56d824",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = TreeExplainer(model)\n",
    "start = time.time()\n",
    "res_shap_py = ex.shap_values(x)\n",
    "time_shap_py = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad6cc0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "res_banz_py = ex.banz_values(x)\n",
    "time_banz_py = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159df599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec44ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = np.asarray(x[:1])\n",
    "ex.brute_banz(line[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c7c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.brute_shap(line[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cbd11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b227893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_cext = {}\n",
    "results_dict_cext['banz'] = {}\n",
    "results_dict_cext['shap'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ae57c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    X, y = make_regression(n_samples=200 * i, n_features=16, n_informative=8,random_state=0, shuffle=False)\n",
    "\n",
    "    model = sklearn.ensemble.RandomForestRegressor(n_estimators=1000 + 100 * i, max_depth=10 + i)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    start = time.time()\n",
    "    res_shap_cext = TreeCext(model).shap_values(x, banz=False)\n",
    "    res_shap = time.time() - start\n",
    "    \n",
    "    start = time.time()\n",
    "    res_banz_cext = TreeCext(model).shap_values(x, banz=True)\n",
    "    res_banz = time.time() - start\n",
    "    \n",
    "    print(res_shap)\n",
    "    print(res_banz)\n",
    "    results_dict_cext['banz'][i] = res_banz\n",
    "    results_dict_cext['shap'][i] = res_shap\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca2a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in results_dict_cext['banz']]\n",
    "a1 = [results_dict_cext['banz'][i] for i in results_dict_cext['banz']]\n",
    "a2 = [results_dict_cext['shap'][i] for i in results_dict_cext['shap']]\n",
    "\n",
    "y_values = {\"banz\": a1, \"treeshap\": a2}\n",
    "labels = [\"BANZ\", \"TREESHAP\"]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.stackplot(x, y_values.values(), labels=labels)\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94305fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_py = {}\n",
    "results_dict_py['banz'] = {}\n",
    "results_dict_py['shap'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b31f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    X, y = make_regression(n_samples=100 + 25 * i, n_features=6, n_informative=2,random_state=0, shuffle=False)\n",
    "\n",
    "    model = sklearn.ensemble.RandomForestRegressor(n_estimators=100 + 25 * i, max_depth=4)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    ex = TreeExplainer(model)\n",
    "    print('created model')\n",
    "    start = time.time()\n",
    "    res_shap_py = ex.shap_values(X)\n",
    "    time_shap_py = time.time() - start\n",
    "    \n",
    "    start = time.time()\n",
    "    res_banz_py = ex.banz_values(X)\n",
    "    time_banz_py = time.time() - start\n",
    "    \n",
    "    print(res_shap_py)\n",
    "    print(res_banz_py)\n",
    "    results_dict_py['banz'][i] = time_banz_py\n",
    "    results_dict_py['shap'][i] = time_shap_py\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d64a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in results_dict_py['banz']]\n",
    "a1 = [results_dict_py['banz'][i] for i in results_dict_py['banz']]\n",
    "a2 = [results_dict_py['shap'][i] for i in results_dict_py['shap']]\n",
    "\n",
    "y_values = {\"banz\": a1, \"treeshap\": a2}\n",
    "labels = [\"BANZ\", \"TREESHAP\"]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.stackplot(x, y_values.values(), labels=labels)\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a4a9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028a93ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee940d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8596c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e4d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c8bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
