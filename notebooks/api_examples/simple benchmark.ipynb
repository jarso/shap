{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "102718eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jarek/projects/shap/venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "import sklearn.ensemble\n",
    "import shap\n",
    "import numpy as np\n",
    "import numba\n",
    "import time\n",
    "import json\n",
    "import xgboost\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap.benchmark\n",
    "\n",
    "from shap import TreeExplainer as TreeCext\n",
    "\n",
    "from shap.explainers.pytree import *\n",
    "\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d072a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a1f0678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
      "13\n",
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "# X,y = shap.datasets.communitiesandcrime()\n",
    "X,y = shap.datasets.boston()\n",
    "print(X.columns.values.tolist())\n",
    "print(len(X.columns.values.tolist()))\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f510ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_explain(name, data, explainer, vals=False):\n",
    "    measure_time = time.perf_counter\n",
    "    start = measure_time()\n",
    "    values = explainer(data)\n",
    "    end = measure_time()\n",
    "    print(\"name: {}, time: {}\".format(name, end - start))\n",
    "    return [name, values if vals else [], end - start]\n",
    "\n",
    "def run_diff_explainers(model, data):\n",
    "\n",
    "#     # use an independent masker\n",
    "#     masker = shap.maskers.Independent(X_train)\n",
    "#     pmasker = shap.maskers.Partition(X_train)\n",
    "    explainers = [\n",
    "        (\"Tree\", shap.explainers.Tree(model)),\n",
    "        (\"TreeBanz\", shap.explainers.Tree(model,  use_banz=True)),\n",
    "        (\"NEW TreeBanz\", shap.explainers.Tree(model,  use_banz=True, change_deltas=True)),\n",
    "    #     (\"Tree approx.\", shap.explainers.Tree(model, masker, approximate=True)),\n",
    "    #     (\"Exact\", shap.explainers.Exact(model.predict, masker)),\n",
    "    ]\n",
    "\n",
    "    return [run_explain(name, data, exp) for name, exp in explainers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e43a06ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_explain2(name, data, explainer):\n",
    "    measure_time = time.perf_counter\n",
    "    start = measure_time()\n",
    "    values = explainer(data)\n",
    "    end = measure_time()\n",
    "    print(\"name: {}, time: {}\".format(name, end - start))\n",
    "    return [name, values, end - start]\n",
    "\n",
    "def run_diff_explainers2(model, data):\n",
    "\n",
    "#     # use an independent masker\n",
    "#     masker = shap.maskers.Independent(X_train)\n",
    "#     pmasker = shap.maskers.Partition(X_train)\n",
    "    explainers = [\n",
    "        (\"Tree\", shap.explainers.Tree(model)),\n",
    "        (\"TreeBanz\", shap.explainers.Tree(model,  use_banz=True)),\n",
    "        (\"NEW TreeBanz\", shap.explainers.Tree(model,  use_banz=True, change_deltas=True)),\n",
    "    #     (\"Tree approx.\", shap.explainers.Tree(model, masker, approximate=True)),\n",
    "    #     (\"Exact\", shap.explainers.Exact(model.predict, masker)),\n",
    "    ]\n",
    "\n",
    "    return [run_explain2(name, data, exp) for name, exp in explainers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b594289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X,y = shap.datasets.boston()\n",
    "# X = X.values\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# model = sklearn.ensemble.RandomForestRegressor(n_estimators=1000, max_depth=13)\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# TreeBanzCext = shap.explainers.Tree(model, use_banz=True, change_deltas=True)\n",
    "# TreeBanzCext(X_test)\n",
    "\n",
    "1\n",
    "# ex = TreeExplainer(model)\n",
    "# res_banz_py = ex.banz_values(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "694370f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zobaczmy na tym datasecie jaka glebokosc daje najlepsze wyszkolenie\n",
    "\n",
    "# X,y = shap.datasets.boston()\n",
    "# X = X.values\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# scores = {}\n",
    "# mean = 5\n",
    "\n",
    "# for i in range(1,13):\n",
    "#     pass\n",
    "#     print(i)\n",
    "#     scores[i] = 0\n",
    "#     for j in range(mean):\n",
    "#         model = sklearn.ensemble.RandomForestRegressor(n_estimators=1000, max_depth=i)\n",
    "#         model.fit(X_train, y_train)\n",
    "#         scores[i] = scores[i] + model.score(X_test, y_test)\n",
    "#     scores[i] = scores[i] / mean\n",
    "\n",
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1009a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_generator(json_input, lookup_key):\n",
    "    if isinstance(json_input, dict):\n",
    "        for k, v in json_input.items():\n",
    "            if k == lookup_key:\n",
    "                yield v\n",
    "            else:\n",
    "                yield from item_generator(v, lookup_key)\n",
    "    elif isinstance(json_input, list):\n",
    "        for item in json_input:\n",
    "            yield from item_generator(item, lookup_key)\n",
    "\n",
    "def tree_depth(json_text):\n",
    "    json_input = json.loads(json_text)\n",
    "    return max(list(item_generator(json_input, 'depth'))) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f6f9a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 12)\n",
      "(506, 13)\n",
      "(1994, 101)\n",
      "(1000, 60)\n",
      "(442, 10)\n",
      "(50, 224, 224, 3)\n",
      "(1000, 60)\n",
      "(150, 4)\n",
      "(14264, 79)\n"
     ]
    }
   ],
   "source": [
    "import shap.datasets as ds\n",
    "\n",
    "def a(x):\n",
    "    X, y = x\n",
    "    print(X.shape)\n",
    "\n",
    "a(ds.adult())\n",
    "a(ds.boston())\n",
    "a(ds.communitiesandcrime())\n",
    "a(ds.corrgroups60())\n",
    "a(ds.diabetes())\n",
    "a(ds.imagenet50())\n",
    "# a(ds.imdb())\n",
    "a(ds.independentlinear60())\n",
    "a(ds.iris())\n",
    "a(ds.nhanesi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c260fa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{1: 0.35595893770551873}\n"
     ]
    }
   ],
   "source": [
    "# Zobaczmy na tym datasecie jaka glebokosc daje najlepsze wyszkolenie\n",
    "\n",
    "X,y = shap.datasets.nhanesi()\n",
    "X = X.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7, test_size=0.2)\n",
    "\n",
    "xgb_full = xgboost.DMatrix(X, label=y)\n",
    "xgb_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "xgb_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "\n",
    "scores = {}\n",
    "mean_depths = {}\n",
    "stddev_depths = {}\n",
    "full_depths = {}\n",
    "\n",
    "mean = 10\n",
    "\n",
    "for i in range(1,2,1):\n",
    "# for i in range(1,32,1):\n",
    "    print(i)\n",
    "    scores[i] = 0\n",
    "    mean_depths[i] = 0\n",
    "    stddev_depths[i] = 0\n",
    "    for j in range(mean):\n",
    "        params = {\n",
    "            \"eta\": 0.002,\n",
    "            \"max_depth\": 3,\n",
    "            \"objective\": \"survival:cox\",\n",
    "            \"subsample\": 0.5\n",
    "        }\n",
    "#         model = xgboost.train(params, xgb_train, 10000, evals = [(xgb_test, \"test\")], verbose_eval=1000)\n",
    "        model = xgboost.XGBRegressor(n_estimators=1000, max_depth=i, subsample=0.5)\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False, early_stopping_rounds=10)\n",
    "        scores[i] = scores[i] + model.score(X_test, y_test)\n",
    "        \n",
    "        booster = model.get_booster()\n",
    "        tree_df = booster.trees_to_dataframe()\n",
    "#         print(\"rysuje drzewo\")\n",
    "#         xgboost.plotting.plot_tree(booster)\n",
    "#         print(booster.get_dump(dump_format = \"json\").head())\n",
    "        depths = [tree_depth(x) for x in booster.get_dump(dump_format = \"json\")]\n",
    "        full_depths[i] = depths\n",
    "        mean_depths[i] = mean_depths[i] + np.mean(depths)\n",
    "        stddev_depths[i] = stddev_depths[i] + np.std(depths)\n",
    "        \n",
    "    scores[i] = scores[i] / mean\n",
    "    mean_depths[i] = mean_depths[i] / mean\n",
    "    stddev_depths[i] = stddev_depths[i] / mean\n",
    "\n",
    "print(scores)\n",
    "# print(mean_depths)\n",
    "# print(stddev_depths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8963df53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-cox-nloglik:9.28408\n",
      "[1000]\ttest-cox-nloglik:8.60854\n",
      "[2000]\ttest-cox-nloglik:8.53116\n",
      "[3000]\ttest-cox-nloglik:8.49403\n",
      "[4000]\ttest-cox-nloglik:8.47058\n",
      "[4999]\ttest-cox-nloglik:8.45255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8354598601693753"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#przyklad lundberga:\n",
    "X,y = shap.datasets.nhanesi()\n",
    "X_display,y_display = shap.datasets.nhanesi(display=True) # human readable feature values\n",
    "\n",
    "xgb_full = xgboost.DMatrix(X, label=y)\n",
    "\n",
    "# create a train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "xgb_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "xgb_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# use validation set to choose # of trees\n",
    "params = {\n",
    "    \"eta\": 0.002,\n",
    "    \"max_depth\": 3,\n",
    "    \"objective\": \"survival:cox\",\n",
    "    \"subsample\": 0.5\n",
    "}\n",
    "# model_train = xgboost.train(params, xgb_train, 10000, evals = [(xgb_test, \"test\")], verbose_eval=1000)\n",
    "\n",
    "# train final model on the full data set\n",
    "params = {\n",
    "    \"eta\": 0.002,\n",
    "    \"max_depth\": 3, \n",
    "    \"objective\": \"survival:cox\",\n",
    "    \"subsample\": 0.5\n",
    "}\n",
    "model_full = xgboost.train(params, xgb_full, 5000, evals = [(xgb_full, \"test\")], verbose_eval=1000)\n",
    "\n",
    "def c_statistic_harrell(pred, labels):\n",
    "    total = 0\n",
    "    matches = 0\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            if labels[j] > 0 and abs(labels[i]) > labels[j]:\n",
    "                total += 1\n",
    "                if pred[j] > pred[i]:\n",
    "                    matches += 1\n",
    "    return matches/total\n",
    "\n",
    "# see how well we can order people by survival\n",
    "c_statistic_harrell(model_full.predict(xgb_test, ntree_limit=5000), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07a45d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.95208156660044\n",
      "-92.30155036647064\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "res = model_full.predict(xgb_test)\n",
    "\n",
    "print(np.sqrt(MSE(res, y_test)))\n",
    "print(r2_score(res, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5659dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048575, 21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    5\n",
       "2    3\n",
       "3    7\n",
       "4    3\n",
       "Name: CLASIFFICATION_FINAL, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "covid = pd.read_csv('../../data/Covid Data.csv')\n",
    "\n",
    "print(covid.shape)\n",
    "\n",
    "cols = ['PNEUMONIA','DIABETES', 'COPD', 'ASTHMA', 'INMSUPR','HIPERTENSION', \n",
    "        'OTHER_DISEASE', 'CARDIOVASCULAR', 'OBESITY','RENAL_CHRONIC', 'TOBACCO']\n",
    "for col in cols :\n",
    "    covid = covid[(covid[col] == 1)|(covid[col] == 2)]\n",
    "    \n",
    "covid['DEATH'] = [2 if row=='9999-99-99' else 1 for row in covid['DATE_DIED']]\n",
    "\n",
    "covid['DEATH'].value_counts()\n",
    "\n",
    "covid.drop(columns=['INTUBED','ICU','DATE_DIED'],inplace=True)\n",
    "\n",
    "covid['PREGNANT'] = covid['PREGNANT'].replace(97,2)\n",
    "covid['PREGNANT'] = covid['PREGNANT'].replace(98,2)\n",
    "\n",
    "y = covid['CLASIFFICATION_FINAL']\n",
    "X = covid.drop('CLASIFFICATION_FINAL', axis=1)\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c9bc407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "testing\n",
      "Logistic Regression Accuracy : 0.5364896040111008\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "print(\"training\")\n",
    "log_reg.fit(X_train, y_train)\n",
    "print(\"testing\")\n",
    "print(\"Logistic Regression Accuracy :\", log_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a41929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7036657f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7baf464d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13: 0.5461856987479942\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5266959630494901"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=13\n",
    "model = sklearn.ensemble.RandomForestClassifier(max_depth=i)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"{}: {}\\n--------------------------------\".format(i, model.score(X_test, y_test)))\n",
    "model_default = sklearn.ensemble.RandomForestClassifier()\n",
    "model_default.fit(X_train, y_train)\n",
    "model_default.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2c002fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205031, 18)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddfd3377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25: (25, 18)\n",
      "ile drzew cext? 100\n",
      "ile drzew cext? 100\n",
      "ile drzew cext? 100\n",
      "uruchamiam z BANZ=False\n",
      "using treeshap and cext\n",
      "here37\n",
      "using dense_Tree_pred\n",
      "name: Tree, time: 3.8095137199998135\n",
      "uruchamiam z BANZ=True\n",
      "using treeshap and cext\n",
      "using BANZ\n",
      "name: TreeBanz, time: 1.1749337759993068\n",
      "uruchamiam z BANZ=True\n",
      "using treeshap and cext\n",
      "using BANZ\n",
      "name: NEW TreeBanz, time: 1.1880112610015203\n",
      "ile drzew cext? 100\n",
      "ile drzew cext? 100\n",
      "ile drzew cext? 100\n",
      "uruchamiam z BANZ=False\n",
      "using treeshap and cext\n",
      "here37\n",
      "using dense_Tree_pred\n",
      "name: Tree, time: 137.19052676699903\n",
      "uruchamiam z BANZ=True\n",
      "using treeshap and cext\n",
      "using BANZ\n",
      "name: TreeBanz, time: 14.832690563998767\n",
      "uruchamiam z BANZ=True\n",
      "using treeshap and cext\n",
      "using BANZ\n",
      "name: NEW TreeBanz, time: 15.107441946000108\n",
      "178.2694239616394\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(25,26,20):\n",
    "    X_2 = X_test[:i]\n",
    "    print(\"{}: {}\".format(i, X_2.shape))\n",
    "    start = time.time()\n",
    "    run_diff_explainers(model, X_2)\n",
    "    run_diff_explainers(model_default, X_2)\n",
    "    print(time.time()-start)\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e0e562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "131792b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train: 71.26990294456482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5474489223580824"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# model = xgboost.XGBClassifier(max_depth=13)\n",
    "model_xgb = xgboost.XGBClassifier()\n",
    "start = time.time()\n",
    "model_xgb.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(\"time to train: {}\".format(end))\n",
    "model_xgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8e01e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205031, 18)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f25e18d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ile drzew cext? 700\n",
      "ile drzew cext? 700\n",
      "ile drzew cext? 700\n",
      "uruchamiam z BANZ=False\n",
      "name: Tree, time: 106.75238401099887\n",
      "uruchamiam z BANZ=True\n",
      "name: TreeBanz, time: 107.43274779199965\n",
      "uruchamiam z BANZ=True\n",
      "name: NEW TreeBanz, time: 109.83415282900023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_diff_explainers(model_xgb, X_test)\n",
    "13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dbb66e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a023f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train: 0.06077218055725098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9814814814814815"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "X, y = load_wine(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3)\n",
    "\n",
    "model = sklearn.ensemble.RandomForestClassifier()\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(\"time to train: {}\".format(end))\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b554ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ile drzew cext? 100\n",
      "ile drzew cext? 100\n",
      "ile drzew cext? 100\n",
      "uruchamiam z BANZ=False\n",
      "using treeshap and cext\n",
      "here37\n",
      "using dense_Tree_pred\n",
      "name: Tree, time: 0.010936492999462644\n",
      "uruchamiam z BANZ=True\n",
      "using treeshap and cext\n",
      "using BANZ\n",
      "name: TreeBanz, time: 0.01636628199958068\n",
      "uruchamiam z BANZ=True\n",
      "using treeshap and cext\n",
      "using BANZ\n",
      "name: NEW TreeBanz, time: 0.01647013399997377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_diff_explainers(model, X)\n",
    "13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b226f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79ace7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "df = pd.read_csv('../../data/Base.csv')\n",
    "# remove \"device_fraud_count\"\n",
    "df = df.drop(['device_fraud_count'], axis=1, errors='ignore') # It's 0 for all rows\n",
    "\n",
    "df['fraud_bool'].value_counts()\n",
    "\n",
    "X = df.drop(['fraud_bool'], axis=1)\n",
    "y = df['fraud_bool']\n",
    "\n",
    "\n",
    "# Train test split by 'month', month 0-5 are train, 6-7 are test data as proposed in the paper\n",
    "X_train = X[X['month']<6]\n",
    "X_test = X[X['month']>=6]\n",
    "y_train = y[X['month']<6]\n",
    "y_test = y[X['month']>=6]\n",
    "\n",
    "X_train.drop('month', axis=1, inplace=True)\n",
    "X_test.drop('month', axis=1, inplace=True)\n",
    "\n",
    "# y_train = le.fit_transform(y_train)\n",
    "# y_test = le.fit_transform(y_test)\n",
    "\n",
    "# onehot encoding for categorical variables\n",
    "s = (X_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "ohe_cols_train = pd.DataFrame(ohe.fit_transform(X_train[object_cols]))\n",
    "ohe_cols_test = pd.DataFrame(ohe.transform(X_test[object_cols]))\n",
    "\n",
    "ohe_cols_train.index = X_train.index\n",
    "ohe_cols_test.index = X_test.index\n",
    "\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_test = X_test.drop(object_cols, axis=1)\n",
    "\n",
    "X_train = pd.concat([num_X_train, ohe_cols_train], axis=1)\n",
    "X_test = pd.concat([num_X_test, ohe_cols_test], axis=1)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d81d896a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train: 121.02144479751587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9859617288828404"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sklearn.ensemble.RandomForestClassifier(max_depth=13)\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(\"time to train: {}\".format(end))\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "562ee3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205011, 50)\n",
      "ile drzew cext? 100\n",
      "ile drzew cext? 100\n",
      "ile drzew cext? 100\n",
      "uruchamiam z BANZ=False\n",
      "using treeshap and cext\n",
      "here37\n",
      "using dense_Tree_pred\n",
      "name: Tree, time: 6.904505259999496\n",
      "uruchamiam z BANZ=True\n",
      "using treeshap and cext\n",
      "using BANZ\n",
      "name: TreeBanz, time: 2.6691520599997602\n",
      "uruchamiam z BANZ=True\n",
      "using treeshap and cext\n",
      "using BANZ\n",
      "name: NEW TreeBanz, time: 2.6810266280008364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "run_diff_explainers(model, X_test[:100])\n",
    "13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26e77e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "depths = [x.get_depth() for x in model.estimators_]\n",
    "print(np.mean(depths))\n",
    "print(np.std(depths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1da19988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train: 146.68317079544067\n",
      "score:0.9859617288828404\n"
     ]
    }
   ],
   "source": [
    "model = sklearn.ensemble.RandomForestClassifier(max_depth=13)\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(\"time to train: {}\".format(end))\n",
    "print(\"score:{}\".format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe8d5c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205011, 50)\n",
      "ile drzew cext? 100\n",
      "ile drzew cext? 100\n",
      "ile drzew cext? 100\n",
      "uruchamiam z BANZ=False\n",
      "using treeshap and cext\n",
      "here37\n",
      "using dense_Tree_pred\n",
      "name: Tree, time: 73.15871214700019\n",
      "uruchamiam z BANZ=True\n",
      "using treeshap and cext\n",
      "using BANZ\n",
      "name: TreeBanz, time: 27.942151048000596\n",
      "uruchamiam z BANZ=True\n",
      "using treeshap and cext\n",
      "using BANZ\n",
      "name: NEW TreeBanz, time: 29.297103109998716\n",
      "13.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "run_diff_explainers(model, X_test[:1000])\n",
    "\n",
    "depths = [x.get_depth() for x in model.estimators_]\n",
    "print(np.mean(depths))\n",
    "print(np.std(depths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81687b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ile drzew cext? 100\n",
      "ile drzew cext? 100\n",
      "ile drzew cext? 100\n",
      "uruchamiam z BANZ=False\n",
      "using treeshap and cext\n",
      "here37\n",
      "using dense_Tree_pred\n",
      "name: Tree, time: 0.7141172869996808\n",
      "uruchamiam z BANZ=True\n",
      "using treeshap and cext\n",
      "using BANZ\n",
      "name: TreeBanz, time: 0.26969660100076\n",
      "uruchamiam z BANZ=True\n",
      "using treeshap and cext\n",
      "using BANZ\n",
      "name: NEW TreeBanz, time: 0.2742919160009478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_diff_explainers(model, X_test[:10])\n",
    "13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a182853",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e4df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(learning_rate=0.09,max_depth=-5,random_state=42)\n",
    "model.fit(X_train,y_train,eval_set=[(X_test,y_test),(X_train,y_train)],\n",
    "          verbose=20,eval_metric='logloss')\n",
    "print('Testing accuracy {:.4f}'.format(model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50753c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_diff_explainers(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef89fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594dada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgboost.XGBClassifier()\n",
    "start = time.time()\n",
    "model_xgb.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(\"time to train: {}\".format(end))\n",
    "model_xgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbf1d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_diff_explainers(model_xgb, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012fde03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "model_cat = catboost.CatBoostClassifier()\n",
    "start = time.time()\n",
    "model_cat.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(\"time to train: {}\".format(end))\n",
    "model_cat.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db0be13",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_diff_explainers(model_cat, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7437e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# koniec czesci nowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683c9870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# narysujmy sobie zaleznosc wytrenowania i glebokosci\n",
    "sns.set()\n",
    "n = max(scores) + 1\n",
    "# n = len(scores) + 1\n",
    "to_plot_scores = [0] * n\n",
    "to_plot_mean = [0] * n\n",
    "to_plot_stddev = [0] * n\n",
    "\n",
    "for i in scores.keys():\n",
    "    print(i)\n",
    "    to_plot_scores[i] = scores[i]\n",
    "    to_plot_mean[i] = mean_depths[i]\n",
    "    to_plot_stddev[i] = stddev_depths[i]\n",
    "    \n",
    "to_plot_scores.remove(0)\n",
    "to_plot_mean.remove(0)\n",
    "to_plot_stddev.remove(0)\n",
    "\n",
    "plt.title(\"Average score of models\")\n",
    "plt.ylabel(\"Accuracy in %\")\n",
    "plt.xlabel(\"Max tree depth\")\n",
    "plt.plot(to_plot_scores)\n",
    "plt.show()\n",
    "    \n",
    "# ax = sns.heatmap(quality)\n",
    "# plt.show()\n",
    "# print(to_plot_mean)\n",
    "# print(to_plot_stddev)\n",
    "\n",
    "plt.title(\"Mean depth of tree in ensemble\")\n",
    "plt.ylabel(\"Mean depth\")\n",
    "plt.xlabel(\"Max tree depth\")\n",
    "plt.errorbar(range(len(to_plot_mean)), to_plot_mean, to_plot_stddev, linestyle='None', marker='^')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbb5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprobujmy odtworzyc ten rezultat\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3)\n",
    "\n",
    "model = xgboost.XGBRegressor(n_estimators=5000, max_depth=2, subsample=0.5)\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False, early_stopping_rounds=10)\n",
    "res = model.predict(X_test)\n",
    "\n",
    "c_statistic_harrell(model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3142ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    model = xgboost.XGBRegressor(n_estimators=1000, max_depth=i, subsample=0.5)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False, early_stopping_rounds=10)\n",
    "    res = model.predict(X_test)\n",
    "\n",
    "    print(\"{}: {}\".format(i, c_statistic_harrell(model.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e6104",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "mean_depths = {}\n",
    "stddev_depths = {}\n",
    "full_depths = {}\n",
    "\n",
    "mean = 10\n",
    "\n",
    "for i in range(1,32):\n",
    "    print(i)\n",
    "    scores[i] = 0\n",
    "    mean_depths[i] = 0\n",
    "    stddev_depths[i] = 0\n",
    "    for j in range(mean):\n",
    "        model = xgboost.XGBRegressor(n_estimators=(100+i*100), max_depth=16, subsample=0.3)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=10, verbose=False)\n",
    "        scores[i] = scores[i] + model.score(X_test, y_test)\n",
    "        \n",
    "        booster = model.get_booster()\n",
    "        tree_df = booster.trees_to_dataframe()\n",
    "#         print(\"rysuje drzewo\")\n",
    "#         xgboost.plotting.plot_tree(booster)\n",
    "        depths = [tree_depth(x) for x in booster.get_dump(dump_format = \"json\")]\n",
    "        full_depths[i] = depths\n",
    "        mean_depths[i] = mean_depths[i] + np.mean(depths)\n",
    "        stddev_depths[i] = stddev_depths[i] + np.std(depths)\n",
    "        \n",
    "    scores[i] = scores[i] / mean\n",
    "    mean_depths[i] = mean_depths[i] / mean\n",
    "    stddev_depths[i] = stddev_depths[i] / mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15eb42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5f1ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# narysujmy sobie zaleznosc wytrenowania i glebokosci w XGBoost\n",
    "sns.set()\n",
    "n = len(scores)\n",
    "to_plot_scores = [0] * n\n",
    "to_plot_mean = [0] * n\n",
    "to_plot_stddev = [0] * n\n",
    "\n",
    "for i in scores.keys():\n",
    "    to_plot_scores[i-1] = scores[i]\n",
    "    to_plot_mean[i-1] = mean_depths[i]\n",
    "    to_plot_stddev[i-1] = stddev_depths[i]\n",
    "\n",
    "plt.title(\"Average score of models\")\n",
    "plt.ylabel(\"Accuracy in %\")\n",
    "plt.xlabel(\"Max tree depth\")\n",
    "plt.plot(to_plot_scores)\n",
    "plt.show()\n",
    "    \n",
    "# ax = sns.heatmap(quality)\n",
    "# plt.show()\n",
    "# print(to_plot_mean)\n",
    "# print(to_plot_stddev)\n",
    "\n",
    "plt.title(\"Mean depth of tree in ensemble\")\n",
    "plt.ylabel(\"Mean depth\")\n",
    "plt.xlabel(\"Max tree depth\")\n",
    "plt.errorbar(range(len(to_plot_mean)), to_plot_mean, to_plot_stddev, linestyle='None', marker='^')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1db2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af13298f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_shap_cext = {}\n",
    "res_banz_cext = {}\n",
    "\n",
    "time_shap_cext = {}\n",
    "time_banz_cext = {}\n",
    "\n",
    "model_quality = {}\n",
    "\n",
    "X,y = shap.datasets.boston()\n",
    "X = X.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "for j in range (2,26,2):\n",
    "    for i in range(100, 1000, 100):\n",
    "        model = sklearn.ensemble.RandomForestRegressor(n_estimators=i, max_depth=j)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        model_quality[(i, j)] = c_statistic_harrell(model.predict(X_test), y_test)\n",
    "        \n",
    "        print(\"------------------------------\")\n",
    "        print(j, i)\n",
    "        print(\"---\")\n",
    "        \n",
    "        start = time.time()\n",
    "        res_shap_cext[(i, j)] = TreeCext(model).shap_values(X_test, banz=False)\n",
    "        time_shap_cext[(i, j)] = time.time() - start\n",
    "        print(time_shap_cext[(i, j)])\n",
    "\n",
    "        start = time.time()\n",
    "        res_banz_cext[(i, j)] = TreeCext(model).shap_values(X_test, banz=True)\n",
    "        time_banz_cext[(i, j)] = time.time() - start\n",
    "        print(time_banz_cext[(i, j)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f2ebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_shap_cext_prop = [ [time_shap_cext[(i, j)] for j in range (2,26,2)] for i in range(100, 1000, 100)]\n",
    "time_banz_cext_prop = [ [time_banz_cext[(i, j)] for j in range (2,26,2)] for i in range(100\n",
    "                                                                                        , 1000, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diffs_banz_shap = \\\n",
    "    [ [ (time_shap_cext[(i, j)] - time_banz_cext[(i, j)]) / time_shap_cext[(i, j)] * 100 \\\n",
    "       for j in range (2,26,2)] for i in range(100, 1000, 100) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5815e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "sns.heatmap(time_diffs_banz_shap, annot=True, fmt=\".1f\", linewidth=.5,\\\n",
    "           xticklabels=range(2,26,2), yticklabels=range(100, 1000, 100))\n",
    "plt.title(\"Percentage of time improvement for TreeShap vs BANZ\")\n",
    "plt.ylabel(\"No. of trees\")\n",
    "plt.xlabel(\"Max tree depth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7e0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_qualities = [[model_quality[(i, j)] for j in range (2,26,2)] for i in range(100, 1000, 100)]\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "sns.heatmap(plot_qualities, annot=True, fmt=\".3f\", linewidth=.5,\\\n",
    "           xticklabels=range(2,26,2), yticklabels=range(100, 1000, 100))\n",
    "plt.title(\"C-index quality for model\")\n",
    "plt.ylabel(\"No. of trees\")\n",
    "plt.xlabel(\"Max tree depth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9effb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_shap_cext_prop = [[res_shap_cext[(i, j)] for j in range (2,26,2)] for i in range(100, 1000, 100)]\n",
    "res_banz_cext_prop = [[res_banz_cext[(i, j)] for j in range (2,26,2)] for i in range(100, 1000, 100)]\n",
    "time_shap_cext_prop = [[time_shap_cext[(i, j)] for j in range (2,26,2)] for i in range(100, 1000, 100)]\n",
    "time_banz_cext_prop = [[time_banz_cext[(i, j)] for j in range (2,26,2)] for i in range(100, 1000, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b677c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87bcfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = shap.datasets.nhanesi()\n",
    "X = X.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7, test_size=0.2)\n",
    "\n",
    "xgb_full = xgboost.DMatrix(X, label=y)\n",
    "xgb_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "xgb_test = xgboost.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15577c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"eta\": 0.2,\n",
    "    \"max_depth\": 4, \n",
    "    \"objective\": \"survival:cox\",\n",
    "    \"subsample\": 0.5,\n",
    "}\n",
    "model_full = xgboost.train(params, xgb_full, 5000, evals = [(xgb_full, \"test\")], verbose_eval=1000,\\\n",
    "                           early_stopping_rounds=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6738d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_statistic_harrell(model_full.predict(xgb_full), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c6c77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d45d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ecb79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_diff_explainers(model_full, xgb_train, xgb_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26803f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa0e22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e56ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgboost.XGBRegressor(n_estimators=1000, max_depth=5, subsample=0.3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=10, verbose=False)\n",
    "\n",
    "booster = model.get_booster()\n",
    "tree_df = booster.trees_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a0ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x * 10 for x in scores.values()])\n",
    "plt.plot(mean_depths.values())\n",
    "plt.plot(stddev_depths.values())\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# wychodza glebokosci po 13 jak da mu sie wolna reke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31105c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58738ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f957cb49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd0bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(attributions):\n",
    "    a = attributions[1000]\n",
    "    # print(a[0][1])\n",
    "\n",
    "\n",
    "#     plt.stackplot(range(len(a[0][1].values[0])), a[0][1].values[0], a[1][1].values[0], a[2][1].values[0],\n",
    "#                  labels=[\"Tree\", \"TreeBanz\", \"NEW TreeBanz\"])\n",
    "    \n",
    "    plt.plot(range(len(a[0][1].values[0])), a[0][1].values[0])\n",
    "    plt.plot(range(len(a[0][1].values[0])), a[1][1].values[0])\n",
    "    plt.plot(range(len(a[0][1].values[0])), a[2][1].values[0])\n",
    "    \n",
    "    plt.legend()\n",
    "    # plt.subplot(a)\n",
    "    plt.show()\n",
    "\n",
    "    shap.plots.bar(a[0][1][0]) #tree\n",
    "    shap.plots.bar(a[1][1][0]) #treeBanz\n",
    "    shap.plots.bar(a[2][1][0]) #NEWtreeBanz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc6e8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X,y = shap.datasets.boston()\n",
    "X = X.values\n",
    "\n",
    "model = xgboost.XGBRegressor(n_estimators=1000, max_depth=32, subsample=0.3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=10, verbose=False)\n",
    "X_eval = X_test[:1]\n",
    "\n",
    "attributions = run_diff_explainers(model, X_train, X_eval)\n",
    "\n",
    "# show_results(attributions)\n",
    "c_statistic_harrell(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38cfd96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1eb457",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X,y = shap.datasets.nhanesi()\n",
    "X = X.values\n",
    "\n",
    "\n",
    "for i in range(1,15):\n",
    "    print(\"i={}\".format(i))\n",
    "    model = sklearn.ensemble.RandomForestRegressor(n_estimators=1000, max_depth=i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    X_eval = X_test[:1]\n",
    "\n",
    "    attributions = run_diff_explainers(model, X_train, X_eval)\n",
    "\n",
    "    y_predict = model.predict(X_test)\n",
    "    # show_results(attributions)\n",
    "    print(\"c-index:{}\".format(c_statistic_harrell(y_predict, y_test)))\n",
    "    print(\"mse:{}\".format(np.sqrt(MSE(y_predict, y_test))))\n",
    "    print(\"----------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9345d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ax = range(len(y_test))\n",
    "plt.figure(figsize=(16, 8), dpi=100)\n",
    "plt.plot(x_ax, y_test, label=\"original\")\n",
    "plt.plot(x_ax, y_predict, label=\"predicted\")\n",
    "plt.title(\"Boston dataset test and predicted data\")\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Price')\n",
    "plt.legend(loc='best',fancybox=True, shadow=True)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae4d5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = {}\n",
    "for i in range(3):\n",
    "    v[i] = [(x / attributions[1000][i][1].values[0][0]) for x in attributions[1000][i][1].values[0]]\n",
    "\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb9e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(a[0][1])\n",
    "shap.plots.beeswarm(a[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afa770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dry run to get all the code warmed up for valid runtime measurements\n",
    "# for name, exp in explainers:\n",
    "#     exp(X_eval[:1])\n",
    "\n",
    "# explain with all the explainers\n",
    "attributions = [run_explain(name, exp, X_eval) for name, exp in explainers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3156f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4422202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=400, n_features=16, n_informative=8,random_state=0, shuffle=False)\n",
    "\n",
    "model = sklearn.ensemble.RandomForestRegressor(n_estimators=1000, max_depth=10)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c255f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bst = xgboost.train({\"learning_rate\": 0.01, \"max_depth\": 4}, xgboost.DMatrix(X, label=y), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef0ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# shap_values = bst.predict(xgboost.DMatrix(X), pred_contribs=True)\n",
    "# print(time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791432a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x = X.head()\n",
    "# x = X[:1]\n",
    "x = X\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5530426",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "res_shap_cext = TreeCext(model).shap_values(X, banz=False)\n",
    "time_shap_cext = time.time() - start\n",
    "time_shap_cext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2cf1db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "res_banz_cext = TreeCext(model).shap_values(X, banz=True)\n",
    "time_banz_cext = time.time() - start\n",
    "time_banz_cext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c740851",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_shap_cext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_banz_cext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0754c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d56d824",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = TreeExplainer(model)\n",
    "start = time.time()\n",
    "res_shap_py = ex.shap_values(x)\n",
    "time_shap_py = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad6cc0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "res_banz_py = ex.banz_values(x)\n",
    "time_banz_py = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159df599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec44ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = np.asarray(x[:1])\n",
    "ex.brute_banz(line[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c7c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.brute_shap(line[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cbd11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b227893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_cext = {}\n",
    "results_dict_cext['banz'] = {}\n",
    "results_dict_cext['shap'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ae57c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    X, y = make_regression(n_samples=200 * i, n_features=16, n_informative=8,random_state=0, shuffle=False)\n",
    "\n",
    "    model = sklearn.ensemble.RandomForestRegressor(n_estimators=1000 + 100 * i, max_depth=10 + i)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    start = time.time()\n",
    "    res_shap_cext = TreeCext(model).shap_values(x, banz=False)\n",
    "    res_shap = time.time() - start\n",
    "    \n",
    "    start = time.time()\n",
    "    res_banz_cext = TreeCext(model).shap_values(x, banz=True)\n",
    "    res_banz = time.time() - start\n",
    "    \n",
    "    print(res_shap)\n",
    "    print(res_banz)\n",
    "    results_dict_cext['banz'][i] = res_banz\n",
    "    results_dict_cext['shap'][i] = res_shap\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca2a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in results_dict_cext['banz']]\n",
    "a1 = [results_dict_cext['banz'][i] for i in results_dict_cext['banz']]\n",
    "a2 = [results_dict_cext['shap'][i] for i in results_dict_cext['shap']]\n",
    "\n",
    "y_values = {\"banz\": a1, \"treeshap\": a2}\n",
    "labels = [\"BANZ\", \"TREESHAP\"]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.stackplot(x, y_values.values(), labels=labels)\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94305fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_py = {}\n",
    "results_dict_py['banz'] = {}\n",
    "results_dict_py['shap'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b31f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    X, y = make_regression(n_samples=100 + 25 * i, n_features=6, n_informative=2,random_state=0, shuffle=False)\n",
    "\n",
    "    model = sklearn.ensemble.RandomForestRegressor(n_estimators=100 + 25 * i, max_depth=4)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    ex = TreeExplainer(model)\n",
    "    print('created model')\n",
    "    start = time.time()\n",
    "    res_shap_py = ex.shap_values(X)\n",
    "    time_shap_py = time.time() - start\n",
    "    \n",
    "    start = time.time()\n",
    "    res_banz_py = ex.banz_values(X)\n",
    "    time_banz_py = time.time() - start\n",
    "    \n",
    "    print(res_shap_py)\n",
    "    print(res_banz_py)\n",
    "    results_dict_py['banz'][i] = time_banz_py\n",
    "    results_dict_py['shap'][i] = time_shap_py\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d64a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in results_dict_py['banz']]\n",
    "a1 = [results_dict_py['banz'][i] for i in results_dict_py['banz']]\n",
    "a2 = [results_dict_py['shap'][i] for i in results_dict_py['shap']]\n",
    "\n",
    "y_values = {\"banz\": a1, \"treeshap\": a2}\n",
    "labels = [\"BANZ\", \"TREESHAP\"]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.stackplot(x, y_values.values(), labels=labels)\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a4a9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028a93ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee940d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8596c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e4d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c8bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
