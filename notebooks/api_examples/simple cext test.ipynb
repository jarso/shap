{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a0935f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jarek/projects/shap/venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=2, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=2, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_features=4, n_informative=2,random_state=0, shuffle=False)\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83eb48a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nasza implementacja banz values\n",
      "other model type\n",
      "uzywajac pythonowego banzhafa\n",
      "{'children_default': array([ 1,  2, -1, -1,  5, -1, -1], dtype=int32),\n",
      " 'children_left': array([ 1,  2, -1, -1,  5, -1, -1], dtype=int32),\n",
      " 'children_right': array([ 4,  3, -1, -1,  6, -1, -1], dtype=int32),\n",
      " 'features': array([ 1,  0, -2, -2,  0, -2, -2], dtype=int32),\n",
      " 'max_depth': 2,\n",
      " 'node_sample_weight': array([100.,  64.,  37.,  27.,  36.,  26.,  10.]),\n",
      " 'thresholds': array([ 0.10953759,  0.43508366, -2.        , -2.        ,  0.76641414,\n",
      "       -2.        , -2.        ]),\n",
      " 'values': array([[ -2.0710816 ],\n",
      "       [-19.7675118 ],\n",
      "       [-34.58580269],\n",
      "       [  0.53903498],\n",
      "       [ 29.38923875],\n",
      "       [ 19.32700042],\n",
      "       [ 55.55105841]])}\n",
      "dwa wymiary\n",
      "betas orig:\n",
      "[1.    0.88  0.08  0.8   0.12  0.035 0.085 1.    1.    1.    1.    1.\n",
      " 1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.\n",
      " 1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.\n",
      " 1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.\n",
      " 1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.\n",
      " 1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.\n",
      " 1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.\n",
      " 1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.\n",
      " 1.    1.    1.    1.    1.   ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[12.062564422604726,\n",
       "  20.69726478249065,\n",
       "  -0.04665993498277235,\n",
       "  0.11276333847589255]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shap.explainers.pytree import *\n",
    "texp = TreeExplainer(regr)\n",
    "texp.banz_values(X[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaccf2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'children_default': array([ 1,  2, -1, -1,  5, -1, -1], dtype=int32),\n",
      " 'children_left': array([ 1,  2, -1, -1,  5, -1, -1], dtype=int32),\n",
      " 'children_right': array([ 4,  3, -1, -1,  6, -1, -1], dtype=int32),\n",
      " 'features': array([ 1,  0, -2, -2,  0, -2, -2], dtype=int32),\n",
      " 'max_depth': 2,\n",
      " 'node_sample_weight': array([100.,  64.,  37.,  27.,  36.,  26.,  10.]),\n",
      " 'thresholds': array([ 0.10953759,  0.43508366, -2.        , -2.        ,  0.76641414,\n",
      "       -2.        , -2.        ]),\n",
      " 'values': array([[-0.02071082],\n",
      "       [-0.19767512],\n",
      "       [-0.34585803],\n",
      "       [ 0.00539035],\n",
      "       [ 0.29389239],\n",
      "       [ 0.19327   ],\n",
      "       [ 0.55551058]])}\n",
      "using treeshap and cext\n",
      "here37\n",
      "using dense_Tree_pred\n",
      "dense tree banz\n",
      "0x7f0bf9ae5f00\n",
      "dla v = 1, betas[v] = 0.32\n",
      "parent\n",
      "0\n",
      "features\n",
      "1\n",
      "deltas\n",
      "0\n",
      "x[y]\n",
      "0.400157\n",
      "czy?\n",
      "0\n",
      "dla v = 2, betas[v] = 0.0925\n",
      "parent\n",
      "1\n",
      "features\n",
      "0\n",
      "deltas\n",
      "0\n",
      "x[y]\n",
      "1.76405\n",
      "czy?\n",
      "0\n",
      "dla v = 3, betas[v] = 0.2275\n",
      "parent\n",
      "1\n",
      "features\n",
      "0\n",
      "deltas\n",
      "2.37037\n",
      "x[y]\n",
      "1.76405\n",
      "czy?\n",
      "0\n",
      "dla v = 4, betas[v] = 0.68\n",
      "parent\n",
      "0\n",
      "features\n",
      "1\n",
      "deltas\n",
      "2.77778\n",
      "x[y]\n",
      "0.400157\n",
      "czy?\n",
      "0\n",
      "dla v = 5, betas[v] = 0.245556\n",
      "parent\n",
      "4\n",
      "features\n",
      "0\n",
      "deltas\n",
      "0\n",
      "x[y]\n",
      "1.76405\n",
      "czy?\n",
      "0\n",
      "dla v = 6, betas[v] = 0.434444\n",
      "parent\n",
      "4\n",
      "features\n",
      "0\n",
      "deltas\n",
      "3.6\n",
      "x[y]\n",
      "1.76405\n",
      "czy?\n",
      "0\n",
      "0 :: 1\n",
      "1 :: 0.32\n",
      "2 :: 0.0925\n",
      "3 :: 0.2275\n",
      "4 :: 0.68\n",
      "5 :: 0.245556\n",
      "6 :: 0.434444\n",
      "test\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. Consider retrying with the feature_perturbation='interventional' option. This check failed because for one of the samples the sum of the SHAP values was -0.020711, while the model output was 0.555511. If this difference is acceptable you can set check_additivity=False to disable this check.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TreeExplainer \u001b[38;5;28;01mas\u001b[39;00m TreeCext\n\u001b[1;32m      2\u001b[0m texp_cext \u001b[38;5;241m=\u001b[39m TreeCext(regr)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtexp_cext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbanz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/shap/venv/lib/python3.10/site-packages/shap-0.40.1-py3.10-linux-x86_64.egg/shap/explainers/_tree.py:415\u001b[0m, in \u001b[0;36mTree.shap_values\u001b[0;34m(self, X, y, tree_limit, approximate, check_additivity, from_call, banz)\u001b[0m\n\u001b[1;32m    413\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_shap_output(phi, flat_output)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_additivity \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_additivity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/projects/shap/venv/lib/python3.10/site-packages/shap-0.40.1-py3.10-linux-x86_64.egg/shap/explainers/_tree.py:549\u001b[0m, in \u001b[0;36mTree.assert_additivity\u001b[0;34m(self, phi, model_output)\u001b[0m\n\u001b[1;32m    547\u001b[0m         check_sum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value[i] \u001b[38;5;241m+\u001b[39m phi[i]\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), model_output[:,i])\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 549\u001b[0m     \u001b[43mcheck_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpected_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mphi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/shap/venv/lib/python3.10/site-packages/shap-0.40.1-py3.10-linux-x86_64.egg/shap/explainers/_tree.py:543\u001b[0m, in \u001b[0;36mTree.assert_additivity.<locals>.check_sum\u001b[0;34m(sum_val, model_output)\u001b[0m\n\u001b[1;32m    539\u001b[0m     err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Consider retrying with the feature_perturbation=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterventional\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m option.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    540\u001b[0m err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This check failed because for one of the samples the sum of the SHAP values\u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    541\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m was \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m, while the model output was \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m. If this difference is acceptable\u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    542\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m you can set check_additivity=False to disable this check.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (sum_val[ind], model_output[ind])\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(err_msg)\n",
      "\u001b[0;31mException\u001b[0m: Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. Consider retrying with the feature_perturbation='interventional' option. This check failed because for one of the samples the sum of the SHAP values was -0.020711, while the model output was 0.555511. If this difference is acceptable you can set check_additivity=False to disable this check."
     ]
    }
   ],
   "source": [
    "from shap import TreeExplainer as TreeCext\n",
    "texp_cext = TreeCext(regr)\n",
    "texp_cext.shap_values(X[:1], banz=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f145ec39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
